# GraphRAG MCP Server

ë…ë¦½ì ì¸ MCP (Model Context Protocol) ì„œë²„ë¡œ GraphRAG ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ Purpose

GraphRAGëŠ” `numpy<2.0`ì„ ìš”êµ¬í•˜ì§€ë§Œ, main backendëŠ” `agent-framework-redis`ë¥¼ ìœ„í•´ `numpy>=2.2.6`ì´ í•„ìš”í•©ë‹ˆë‹¤. ì´ ì¶©ëŒì„ í•´ê²°í•˜ê¸° ìœ„í•´ GraphRAGë¥¼ **ë…ë¦½ í”„ë¡œì„¸ìŠ¤**ë¡œ ì‹¤í–‰í•˜ì—¬ numpy ë²„ì „ì„ ê²©ë¦¬í•©ë‹ˆë‹¤.

## ğŸ“¦ Architecture

```
Main Backend (numpy>=2.2.6)
    â†“ stdio MCP protocol
GraphRAG MCP Server (numpy<2.0) â† Isolated venv
    â†“ subprocess calls
GraphRAG CLI (python -m graphrag.index/query)
```

## ğŸš€ Installation

### ìë™ ì„¤ì¹˜ (ê¶Œì¥)

```bash
cd /afh/code/multi-agent-doc-research/graphrag_mcp_server
./run_server.sh  # ìë™ìœ¼ë¡œ venv ìƒì„± ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜
```

### ìˆ˜ë™ ì„¤ì¹˜

```bash
cd /afh/code/multi-agent-doc-research/graphrag_mcp_server

# 1. ê°€ìƒí™˜ê²½ ìƒì„±
python3 -m venv .venv
source .venv/bin/activate

# 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install --upgrade pip
pip install -e .

# 3. ì„œë²„ ì‹¤í–‰
python -m graphrag_mcp_server.server
```

## âš™ï¸ Environment Variables

ë‹¤ìŒ í™˜ê²½ ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤ (`.env` íŒŒì¼ ë˜ëŠ” ì‹œìŠ¤í…œ í™˜ê²½):

```bash
# Azure OpenAI (GraphRAG ì¸ë±ì‹±/ê²€ìƒ‰ì— ì‚¬ìš©)
AZURE_OPENAI_API_KEY=your_key
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o
AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME=text-embedding-3-large
AZURE_OPENAI_API_VERSION=2024-08-01-preview

# GraphRAG ë°ì´í„° ê²½ë¡œ
GRAPHRAG_ROOT=./graphrag
```

## ğŸ”§ MCP Tools

GraphRAG MCP ì„œë²„ëŠ” 3ê°œì˜ MCP toolì„ ì œê³µí•©ë‹ˆë‹¤:

### 1. index_documents

Markdown íŒŒì¼ë“¤ì„ GraphRAG í˜•ì‹ìœ¼ë¡œ ì¸ë±ì‹±í•©ë‹ˆë‹¤.

**Parameters:**
- `markdown_files` (array of strings): ì¸ë±ì‹±í•  markdown íŒŒì¼ ê²½ë¡œë“¤
- `force_reindex` (boolean, optional): ê°•ì œ ì¬ì¸ë±ì‹± ì—¬ë¶€ (ê¸°ë³¸ê°’: false)

**Returns:**
```json
{
  "status": "success",
  "message": "Indexed 5 files",
  "files_indexed": 5,
  "output_dir": "/path/to/graphrag/output"
}
```

### 2. local_search

ì—”í‹°í‹° ì¤‘ì‹¬ì˜ ìƒì„¸í•œ ê²€ìƒ‰ (íŠ¹ì • ê°œì²´/ì¸ë¬¼/ì¡°ì§ì— ëŒ€í•œ ì§ˆë¬¸ì— ì í•©)

**Parameters:**
- `query` (string): ê²€ìƒ‰ ì¿¼ë¦¬
- `top_k` (integer, optional): ë°˜í™˜í•  ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 10)

**Returns:**
```json
{
  "status": "success",
  "query": "ì£¼ìš” ì‚¬ì—… ì „ëµì€?",
  "response": "ìƒì„¸í•œ ê²€ìƒ‰ ê²°ê³¼...",
  "search_type": "local"
}
```

### 3. global_search

ì»¤ë®¤ë‹ˆí‹° ì¤‘ì‹¬ì˜ ì£¼ì œë³„ ê²€ìƒ‰ (ì „ì²´ ë¬¸ì„œì˜ ì£¼ì œ/íŠ¸ë Œë“œ ì§ˆë¬¸ì— ì í•©)

**Parameters:**
- `query` (string): ê²€ìƒ‰ ì¿¼ë¦¬

**Returns:**
```json
{
  "status": "success",
  "query": "ì „ì²´ ë¬¸ì„œì˜ ì£¼ìš” ì£¼ì œëŠ”?",
  "response": "ì¢…í•©ì ì¸ ê²€ìƒ‰ ê²°ê³¼...",
  "search_type": "global"
}
```

## ğŸ“ Project Structure

```
graphrag_mcp_server/
â”œâ”€â”€ graphrag_mcp_server/          # Package directory
â”‚   â”œâ”€â”€ __init__.py               # Package initialization
â”‚   â””â”€â”€ server.py                 # MCP server implementation (450+ lines)
â”œâ”€â”€ pyproject.toml                # Package configuration
â”œâ”€â”€ run_server.sh                 # Server startup script
â”œâ”€â”€ .venv/                        # Isolated Python environment (numpy<2.0)
â””â”€â”€ README.md                     # This file
```

## ğŸ”Œ Integration with Backend

### Semantic Kernel Plugin

```python
from services_sk.graphrag_mcp_plugin import GraphRAGMCPPlugin

plugin = GraphRAGMCPPlugin()

# Index documents
result = await plugin.index_documents(
    markdown_files=json.dumps(["/path/to/doc1.md", "/path/to/doc2.md"])
)

# Local search
result = await plugin.local_search(
    query="ì£¼ìš” ì‚¬ì—…ì€?",
    top_k=10
)

# Global search
result = await plugin.global_search(query="ì „ì²´ ì£¼ì œëŠ”?")

# Cleanup
await plugin.cleanup()
```

### Agent Framework Executor

```python
from services_afw.graphrag_executor import GraphRAGExecutor

executor = GraphRAGExecutor()

# Via workflow context
await executor.index_documents(
    ctx=workflow_context,
    workflow_input={"markdown_files": [...]}
)

await executor.local_search(
    ctx=workflow_context,
    workflow_input={"query": "...", "top_k": 10}
)
```

## ğŸ§ª Testing

```bash
# Backend í…ŒìŠ¤íŠ¸ ì‹¤í–‰
cd /afh/code/multi-agent-doc-research/app/backend
pytest tests/test_graphrag_mcp.py -v -s
```

í…ŒìŠ¤íŠ¸ëŠ” ë‹¤ìŒ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤:
1. PDF ì—…ë¡œë“œ ë° Markdown ìƒì„±
2. GraphRAG ì¸ë±ì‹± (MCP Plugin)
3. GraphRAG ì¸ë±ì‹± (AFW Executor)
4. Local Search (MCP Plugin)
5. Local Search (AFW Executor)
6. Global Search (MCP Plugin)
7. Global Search (AFW Executor)
8. ì—°ê²° ì •ë¦¬

## ğŸ“Š Data Flow

```
1. Upload PDF
   â†“
2. Document Intelligence â†’ Markdown
   â†“
3. Save to graphrag/input/*.md
   â†“
4. MCP Client calls index_documents
   â†“
5. MCP Server runs: python -m graphrag.index --root ./graphrag
   â†“
6. GraphRAG creates parquet files in output/
   â†“
7. Search via local_search or global_search
   â†“
8. Results returned to backend
```

## ğŸ› ï¸ Troubleshooting

### "Unable to determine which files to ship"

**ì›ì¸**: hatchlingì´ íŒ¨í‚¤ì§€ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì§€ ëª»í•¨

**í•´ê²°**:
```bash
# êµ¬ì¡°ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸:
graphrag_mcp_server/
  graphrag_mcp_server/  # íŒ¨í‚¤ì§€ ë””ë ‰í† ë¦¬ (NOT root)
    __init__.py
    server.py
  pyproject.toml
```

### "ModuleNotFoundError: No module named 'graphrag_mcp_server'"

**ì›ì¸**: íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ

**í•´ê²°**:
```bash
cd graphrag_mcp_server
source .venv/bin/activate
pip install -e .
```

### "numpy version conflict"

**ì›ì¸**: main backendì˜ numpy>=2.2.6ì™€ ì¶©ëŒ

**í•´ê²°**: MCP ì„œë²„ëŠ” **ë…ë¦½ venv**ì—ì„œ ì‹¤í–‰ë˜ë¯€ë¡œ ì¶©ëŒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. `run_server.sh`ë¥¼ ì‚¬ìš©í•˜ë©´ ìë™ìœ¼ë¡œ ê²©ë¦¬ë©ë‹ˆë‹¤.

## ğŸ“– GraphRAG Settings

ì¸ë±ì‹± ì‹œ ìë™ìœ¼ë¡œ ìƒì„±ë˜ëŠ” `settings.yaml`:

```yaml
llm:
  api_key: ${AZURE_OPENAI_API_KEY}
  type: azure_openai_chat
  model: gpt-4o
  api_base: ${AZURE_OPENAI_ENDPOINT}
  api_version: ${AZURE_OPENAI_API_VERSION}
  deployment_name: ${AZURE_OPENAI_DEPLOYMENT_NAME}

embeddings:
  async_mode: threaded
  llm:
    api_key: ${AZURE_OPENAI_API_KEY}
    type: azure_openai_embedding
    model: text-embedding-3-large
    api_base: ${AZURE_OPENAI_ENDPOINT}
    api_version: ${AZURE_OPENAI_API_VERSION}
    deployment_name: ${AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME}

input:
  type: file
  file_type: text
  base_dir: "input"
  
# ... more GraphRAG settings
```

## ğŸ”— References

- [GraphRAG Documentation](https://microsoft.github.io/graphrag/)
- [MCP Protocol Specification](https://github.com/modelcontextprotocol/specification)
- [Agent Framework](https://github.com/microsoft/agent-framework)
- [Semantic Kernel](https://github.com/microsoft/semantic-kernel)

## ğŸ“ License

Same as parent project (multi-agent-doc-research)
